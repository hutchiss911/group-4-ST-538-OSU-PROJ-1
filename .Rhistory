select(-ST, -SERIALNO, -WGTP, -PWGTP)
head(puma_data)
#Convert education levels
puma_data <- puma_data %>%
mutate(
EducationLevel = case_when(
EducationLevel == "bb" ~ "00",
TRUE ~ EducationLevel
),
EducationLevel = as.numeric(EducationLevel)
)
#Make sure it is numeric
class(puma_data$EducationLevel)
##Group education level
puma_data <- puma_data %>%
mutate(
EducationGroup = cut(EducationLevel, breaks = c(0, 2, 11, 16, 20, 21, 22, 24, Inf),
labels = c("No schooling completed", "Less than High School",
"High School", "high school diploma or GED",
"Associates Degree", "Bachelors Degree",
"Masters Degree", "Doctorate Degree"),
right = FALSE)
)
unique(puma_data$EducationGroup)
puma_data[1:50,]
#Rearrange the columns
puma_data <- puma_data %>%
select(EducationGroup, EducationLevel, Income, Age, Sex, PersonNumber)
head(puma_data)
#Drop age below 14
puma_data <- puma_data %>%
filter(Age >= 14)
head(puma_data[puma_data$Age < 14,])
#Identify gender
puma_data <- puma_data %>%
mutate(
Sex = case_when(
Sex == 1 ~ "Male",
Sex == 2 ~ "Female",
TRUE ~ as.character(Sex)
)
)
head(puma_data)
### Explore the data
#Summarizing the ranges of numerical
summary(puma_data$Age) #Range of Age
summary(puma_data$Income) #Range of Age
summary(puma_data$EducationNumber) #Range of Education
table(puma_data$EducationLevel) #Count of each level of education
#Plot inceom distribution
ggplot(puma_data %>% filter(Income > 0), aes(Income)) +
geom_histogram(binwidth = 10000) +
scale_x_continuous(labels = function(x) paste0(x / 1000, "K")) +
labs(title = "Income Distribution in Oregon"
, x = "Income by $10k"
, y = "Count of Individuals") +
theme_minimal()
##[Reference on Variables for now](https://usa.ipums.org/usa/resources/codebooks/DataDict1822.pdf)
### Model the data
#Drop zero income from the data set
#Drop observation with 0 income (unemployed individuals)
puma_data <- puma_data[puma_data$Income != 0, ]
puma_data
head(puma_data)
# Does higher education mean higher income accounting for sex and age?
model_1 <- lm(Income ~ EducationGroup + Sex + Age, data = puma_data)
model_2 <- lm(Income ~ EducationGroup + Sex * Age, data = puma_data)
model_3 <- lm(Income ~ EducationGroup * Sex + Age, data = puma_data)
model_4 <- lm(Income ~ EducationGroup * Sex * Age, data = puma_data)
#Compare model 3 and 4
anova(model_3, model_4)
#The full model provides a significantly better fit.
#Compare model 2 and 4
anova(model_2, model_4)
#Model 4 is a better fit.
#Compare model 1 and 4
anova(model_1, model_4)
##Check the assumption
#Linearity and Homoscedasticity assumption
plot(fitted(model_4), residuals(model_4))
#Normality assumption
qqnorm(residuals(model_4))
qqline(residuals(model_4))
#Independence assumptions
plot(residuals(model_4))
#Fitted vs residuals plot exhibiting pattern
#Consider log transformation of the response variable:
#Logged models
model_5 <- lm(log(Income) ~ EducationGroup + Sex + Age, data = puma_data, na.action = na.exclude)
model_6 <- lm(log(Income) ~ EducationGroup + Sex * Age, data = puma_data, na.action = na.exclude)
model_7 <- lm(log(Income) ~ EducationGroup * Sex + Age, data = puma_data, na.action = na.exclude)
model_8 <- lm(log(Income) ~ EducationGroup * Sex * Age, data = puma_data, na.action = na.exclude)
#Compare models 7 and 8
anova(model_7, model_8)
#Compare models 6 and 8
anova(model_6, model_8)
#Compare models 5 and 8
anova(model_5, model_8)
#Model 8 is the best from 4 models
#Check the assumption
#Linear regression assumption
plot(fitted(model_8), residuals(model_8))
#Normality assumption
qqnorm(residuals(model_8))
qqline(residuals(model_8))
#Use predict() to fit the regression and find the average income for 50 YO males
new_data_1 <- data.frame(EducationGroup = c("No schooling completed","Less than High School", "High School", "high school diploma or GED","Associates Degree", "Bachelors Degree", "Masters Degree", "Doctorate Degree"),
Sex = "Male",
Age = 50)
mu_1 <- predict(model_8, newdata = new_data_1 , type = "response")
exp(mu_1)
#Use predict() to fit the regression and find the average income for 50 YO femails
new_data_2 <- data.frame(EducationGroup = c("No schooling completed","Less than High School", "High School", "high school diploma or GED","Associates Degree", "Bachelors Degree", "Masters Degree", "Doctorate Degree"),
Sex = "Female",
Age = 50)
mu_2 <- predict(model_8, newdata = new_data_2 , type = "response")
exp(mu_2)
puma_data_q2 <- puma_data %>%
select(EducationGroup, Income, Race, OccupationGroup)
## For your notes, an if statement for checking if a package is installed :)
#if(!require(somepackage)){
#    install.packages("somepackage")
#    library(somepackage)
#}
if (!require(tidycensus)) {
install.packages("tidycensus")
}
if (!require(tidyverse)) {
install.packages("tidyverse")
}
if (!require(dplyr)) {
install.packages("dplyr")
}
if (!require(ggplot2)) {
install.packages("ggplot2")
}
#Load libraries
library(tidycensus)
library(tidyverse)
library(dplyr)
library(ggplot2)
census_api_key("2547c95ce33b1ed0eec3aafd0fd8526a5bb9a22e")
#Pull data set for specific variables
puma_data <- get_pums(variables = c("AGEP","SCHL","PINCP", "SEX", "RAC1P", "TEN", "OCCP")
,state = "OR"
,year = 2022)
#Rename the columns
puma_data <- puma_data %>% rename(Age = AGEP,
EducationLevel = SCHL,
Income = PINCP,
Sex = SEX,
PersonNumber = SPORDER,
Race = RAC1P,
Homeownership = TEN,
Occupation = OCCP)
head(puma_data[, 2:8])
#Remove columns that are not needed
puma_data <- puma_data %>%
select(-ST, -SERIALNO, -WGTP, -PWGTP)
head(puma_data)
#Convert education levels
puma_data <- puma_data %>%
mutate(
EducationLevel = case_when(
EducationLevel == "bb" ~ "00",
TRUE ~ EducationLevel
),
EducationLevel = as.numeric(EducationLevel)
)
#Convert Occupation to numerical
puma_data <- puma_data %>%
mutate(
Occupation = case_when(
Occupation == "bbbb" ~ "0000",
Occupation == "000N" ~ "0000",
TRUE ~ Occupation
),
Occupation = as.numeric(Occupation)
)
#Make sure it is numeric
class(puma_data$EducationLevel)
#Convert homeownership
puma_data <- puma_data %>%
mutate(
Homeownership = case_when(
Homeownership == "b" ~ "0",
TRUE ~ Homeownership
),
Homeownership = as.numeric(Homeownership)
)
##Group education level
puma_data <- puma_data %>%
mutate(
EducationGroup = cut(EducationLevel, breaks = c(0, 2, 11, 16, 20, 21, 22, 24, Inf),
labels = c("No schooling completed", "Less than High School",
"High School", "high school diploma or GED",
"Associates Degree", "Bachelors Degree",
"Masters Degree", "Doctorate Degree"),
right = FALSE)
)
unique(puma_data$EducationGroup)
puma_data[1:50,]
#Rearange the columns
puma_data <- puma_data %>%
select(EducationGroup, EducationLevel, Income, Occupation, Age, Sex, Race, Homeownership, PersonNumber)
head(puma_data)
#Drop age below 14
puma_data <- puma_data %>%
filter(Age >= 14)
head(puma_data[puma_data$Age < 14,])
#relabelling race
puma_data <- puma_data %>%
mutate(
Race = case_when(
Race == 1 ~ "White alone",
Race == 2 ~ "Black or African American alone",
Race == 3 ~ "American Indian alone",
Race == 4 ~ "Alaska Native alone",
Race == 5 ~ "Native American Not Specified",
Race == 6 ~ "Asian alone",
Race == 7 ~ "Native Hawaiian and Other Pacific Islander alone",
Race == 8 ~ "Some Other Race alone",
Race == 9 ~ "Two or More Races",
TRUE ~ as.character(Race)
)
)
#relabelling tenure
puma_data <- puma_data %>%
mutate(
Homeownership = case_when(
Homeownership == 0 ~ "N/A",
Homeownership == 1 ~ "Owned with mortgage or loan",
Homeownership == 2 ~ "Owned free and clear",
Homeownership == 3 ~ "Rented",
Homeownership == 4 ~ "Occupied without payment of rent",
TRUE ~ as.character(Homeownership)
)
)
puma_data[1:100,]
#Identify gender
puma_data <- puma_data %>%
mutate(
Sex = case_when(
Sex == 1 ~ "Male",
Sex == 2 ~ "Female",
TRUE ~ as.character(Sex)
)
)
head(puma_data)
#Occupation Grouping
puma_data <- puma_data %>%
mutate(
OccupationGroup = case_when(
between(as.numeric(Occupation), 0000, 0009) ~ "Less than 16 years old",
between(as.numeric(Occupation), 0010, 0440) ~ "Management",
between(as.numeric(Occupation), 0500, 0960) ~ "Business/Finance",
between(as.numeric(Occupation), 1000, 1240) ~ "CS/Math/Statistics",
between(as.numeric(Occupation), 1300, 1560) ~ "Engineering/Architecture",
between(as.numeric(Occupation), 1600, 1980) ~ "Science/Economics",
between(as.numeric(Occupation), 2000, 2060) ~ "Social/Therapy/Religious",
between(as.numeric(Occupation), 2100, 2180) ~ "Legal",
between(as.numeric(Occupation), 2200, 2555) ~ "Education/Library",
between(as.numeric(Occupation), 2600, 2920) ~ "Entertainment/Arts/Media/Sports",
between(as.numeric(Occupation), 3000, 3550) ~ "Medical",
between(as.numeric(Occupation), 3600, 3655) ~ "Health",
between(as.numeric(Occupation), 3700, 3960) ~ "Protective/Essential",
between(as.numeric(Occupation), 4000, 4160) ~ "Food",
between(as.numeric(Occupation), 4200, 4255) ~ "Sanitation/Groundskeeping",
between(as.numeric(Occupation), 4300, 4655) ~ "Personal/Lifestyle",
between(as.numeric(Occupation), 4700, 4965) ~ "Sales",
between(as.numeric(Occupation), 5000, 5940) ~ "Office/Administrative",
between(as.numeric(Occupation), 6005, 6130) ~ "Farming/Fishing/Forestry",
between(as.numeric(Occupation), 6200, 6765) ~ "Construction",
between(as.numeric(Occupation), 6800, 6950) ~ "BlueCollar",
between(as.numeric(Occupation), 7000, 7640) ~ "Repairs/Mechanics",
between(as.numeric(Occupation), 7700, 8990) ~ "Manufacturing",
between(as.numeric(Occupation), 9005, 9760) ~ "Transportation",
between(as.numeric(Occupation), 9800, 9830) ~ "Military",
TRUE ~ "Not Classified"
)
)
#Summarizing the ranges of numerical
summary(puma_data$Age) #Range of Age
summary(puma_data$Income) #Range of Age
summary(puma_data$EducationLevel) #Range of Education
table(puma_data$EducationGroup) #Count of each level of education
table(puma_data$Race) #Count of each race
table(puma_data$Homeownership) #Count of each Homeownership
#Plot income distribution
ggplot(puma_data %>% filter(Income > 0), aes(Income)) +
geom_histogram(binwidth = 10000) +
scale_x_continuous(labels = function(x) paste0(x / 1000, "K")) +
labs(title = "Income Distribution in Oregon"
, x = "Income by $10k"
, y = "Count of Individuals") +
theme_minimal()
#Drop zero income from the data set
#Drop observation with 0 income (unemployed individuals)
puma_data <- puma_data[puma_data$Income != 0, ]
puma_data
head(puma_data)
# Does higher education mean higher income accounting for sex and age?
model_1 <- lm(Income ~ EducationGroup + Sex + Age, data = puma_data)
model_2 <- lm(Income ~ EducationGroup + Sex * Age, data = puma_data)
model_3 <- lm(Income ~ EducationGroup * Sex + Age, data = puma_data)
model_4 <- lm(Income ~ EducationGroup * Sex * Age, data = puma_data)
#Compare model 3 and 4
anova(model_3, model_4)
#The full model provides a significantly better fit.
#Compare model 2 and 4
anova(model_2, model_4)
#Model 4 is a better fit.
#Compare model 1 and 4
anova(model_1, model_4)
#Linearity and Homoscedasticity assumption
plot(fitted(model_4), residuals(model_4))
#Normality assumption
qqnorm(residuals(model_4))
qqline(residuals(model_4))
#Independence assumptions
plot(residuals(model_4))
#Fitted vs residuals plot exhibiting pattern
#Logged models
model_5 <- lm(log(Income) ~ EducationGroup + Sex + Age, data = puma_data, na.action = na.exclude)
model_6 <- lm(log(Income) ~ EducationGroup + Sex * Age, data = puma_data, na.action = na.exclude)
model_7 <- lm(log(Income) ~ EducationGroup * Sex + Age, data = puma_data, na.action = na.exclude)
model_8 <- lm(log(Income) ~ EducationGroup * Sex * Age, data = puma_data, na.action = na.exclude)
#Compare models 7 and 8
anova(model_7, model_8)
#Compare models 6 and 8
anova(model_6, model_8)
#Compare models 5 and 8
anova(model_5, model_8)
#Model 8 is the best from 4 models
#Linear regression assumption
plot(fitted(model_8), residuals(model_8))
#Normality assumption
qqnorm(residuals(model_8))
qqline(residuals(model_8))
#Use predict() to fit the regression and find the average income
new_data_1 <- data.frame(EducationGroup = c("No schooling completed","Less than High School", "High School", "high school diploma or GED","Associates Degree", "Bachelors Degree", "Masters Degree", "Doctorate Degree"),
Sex = "Male",
Age = 50)
mu_1 <- predict(model_8, newdata = new_data_1 , type = "response")
exp(mu_1)
#Use predict() to fit the regression and find the average income
new_data_2 <- data.frame(EducationGroup = c("No schooling completed","Less than High School", "High School", "high school diploma or GED","Associates Degree", "Bachelors Degree", "Masters Degree", "Doctorate Degree"),
Sex = "Female",
Age = 50)
mu_2 <- predict(model_8, newdata = new_data_2 , type = "response")
exp(mu_2)
# Can we predict household income based on education, occupation, and race/ethnicity?
head(puma_data)
puma_data_q2 <- puma_data |>
select(EducationGroup, Income, Race, OccupationGroup)
head(puma_data_q2)
## An if statement for checking if a package is installed :)
#if(!require(somepackage)){
#    install.packages("somepackage")
#    library(somepackage)
#}
if (!require(tidycensus)) {
install.packages("tidycensus")
}
if (!require(tidyverse)) {
install.packages("tidyverse")
}
if (!require(dplyr)) {
install.packages("dplyr")
}
if (!require(ggplot2)) {
install.packages("ggplot2")
}
#Load libraries
library(tidycensus)
library(tidyverse)
library(dplyr)
library(ggplot2)
census_api_key("2547c95ce33b1ed0eec3aafd0fd8526a5bb9a22e")
### Obtain the Data
#Pull data set for specific variables
puma_data <- get_pums(variables = c("AGEP","SCHL","PINCP", "SEX", "RAC1P", "TEN")
,state = "OR"
,year = 2022)
#Rename the columns
puma_data <- puma_data %>% rename(Age = AGEP,
EducationLevel = SCHL,
Income = PINCP,
Sex = SEX,
PersonNumber = SPORDER)
head(puma_data[, 2:5])
#Remove columns that are not needed
puma_data <- puma_data %>%
select(-ST, -SERIALNO, -WGTP, -PWGTP)
head(puma_data)
#Convert education levels
puma_data <- puma_data %>%
mutate(
EducationLevel = case_when(
EducationLevel == "bb" ~ "00",
TRUE ~ EducationLevel
),
EducationLevel = as.numeric(EducationLevel)
)
#Make sure it is numeric
class(puma_data$EducationLevel)
##Group education level
puma_data <- puma_data %>%
mutate(
EducationGroup = cut(EducationLevel, breaks = c(0, 2, 11, 16, 20, 21, 22, 24, Inf),
labels = c("No schooling completed", "Less than High School",
"High School", "high school diploma or GED",
"Associates Degree", "Bachelors Degree",
"Masters Degree", "Doctorate Degree"),
right = FALSE)
)
unique(puma_data$EducationGroup)
puma_data[1:50,]
#Rearrange the columns
puma_data <- puma_data %>%
select(EducationGroup, EducationLevel, Income, Age, Sex, PersonNumber)
head(puma_data)
#Drop age below 14
puma_data <- puma_data %>%
filter(Age >= 14)
head(puma_data[puma_data$Age < 14,])
#Identify gender
puma_data <- puma_data %>%
mutate(
Sex = case_when(
Sex == 1 ~ "Male",
Sex == 2 ~ "Female",
TRUE ~ as.character(Sex)
)
)
head(puma_data)
### Explore the data
#Summarizing the ranges of numerical
summary(puma_data$Age) #Range of Age
summary(puma_data$Income) #Range of Age
summary(puma_data$EducationNumber) #Range of Education
table(puma_data$EducationLevel) #Count of each level of education
#Plot inceom distribution
ggplot(puma_data %>% filter(Income > 0), aes(Income)) +
geom_histogram(binwidth = 10000) +
scale_x_continuous(labels = function(x) paste0(x / 1000, "K")) +
labs(title = "Income Distribution in Oregon"
, x = "Income by $10k"
, y = "Count of Individuals") +
theme_minimal()
##[Reference on Variables for now](https://usa.ipums.org/usa/resources/codebooks/DataDict1822.pdf)
### Model the data
#Drop zero income from the data set
#Drop observation with 0 income (unemployed individuals)
puma_data <- puma_data[puma_data$Income != 0, ]
puma_data
head(puma_data)
# Does higher education mean higher income accounting for sex and age?
model_1 <- lm(Income ~ EducationGroup + Sex + Age, data = puma_data)
model_2 <- lm(Income ~ EducationGroup + Sex * Age, data = puma_data)
model_3 <- lm(Income ~ EducationGroup * Sex + Age, data = puma_data)
model_4 <- lm(Income ~ EducationGroup * Sex * Age, data = puma_data)
#Compare model 3 and 4
anova(model_3, model_4)
#The full model provides a significantly better fit.
#Compare model 2 and 4
anova(model_2, model_4)
#Model 4 is a better fit.
#Compare model 1 and 4
anova(model_1, model_4)
##Check the assumption
#Linearity and Homoscedasticity assumption
plot(fitted(model_4), residuals(model_4))
#Normality assumption
qqnorm(residuals(model_4))
qqline(residuals(model_4))
#Independence assumptions
plot(residuals(model_4))
#Fitted vs residuals plot exhibiting pattern
#Consider log transformation of the response variable:
#Logged models
model_5 <- lm(log(Income) ~ EducationGroup + Sex + Age, data = puma_data, na.action = na.exclude)
model_6 <- lm(log(Income) ~ EducationGroup + Sex * Age, data = puma_data, na.action = na.exclude)
model_7 <- lm(log(Income) ~ EducationGroup * Sex + Age, data = puma_data, na.action = na.exclude)
model_8 <- lm(log(Income) ~ EducationGroup * Sex * Age, data = puma_data, na.action = na.exclude)
#Compare models 7 and 8
anova(model_7, model_8)
#Compare models 6 and 8
anova(model_6, model_8)
#Compare models 5 and 8
anova(model_5, model_8)
#Model 8 is the best from 4 models
#Check the assumption
#Linear regression assumption
plot(fitted(model_8), residuals(model_8))
#Normality assumption
qqnorm(residuals(model_8))
qqline(residuals(model_8))
#Use predict() to fit the regression and find the average income for 50 YO males
new_data_1 <- data.frame(EducationGroup = c("No schooling completed","Less than High School", "High School", "high school diploma or GED","Associates Degree", "Bachelors Degree", "Masters Degree", "Doctorate Degree"),
Sex = "Male",
Age = 50)
mu_1 <- predict(model_8, newdata = new_data_1 , type = "response")
exp(mu_1)
#Use predict() to fit the regression and find the average income for 50 YO femails
new_data_2 <- data.frame(EducationGroup = c("No schooling completed","Less than High School", "High School", "high school diploma or GED","Associates Degree", "Bachelors Degree", "Masters Degree", "Doctorate Degree"),
Sex = "Female",
Age = 50)
mu_2 <- predict(model_8, newdata = new_data_2 , type = "response")
exp(mu_2)
lmod <- lm(sr ~ X - 1, data = savings)
head(savings)
